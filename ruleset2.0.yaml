modelVersion: 2.0

description: "Data Catalog"

docker-images:
  - adp-helm-dr-check: armdocker.rnd.ericsson.se/sandbox/adp-staging/adp-cicd/common-library-adp-helm-dr-check:latest
  - doc-builder: armdocker.rnd.ericsson.se/sandbox/adp-staging/adp-cicd/bob-docbuilder:41a32e6
  - k8-test: armdocker.rnd.ericsson.se/sandbox/adp-staging/adp-cicd/bob-py3kubehelmbuilder:latest
  - k8s-test: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/bob-py3kubehelmbuilder:latest
  - adp-release-auto: armdocker.rnd.ericsson.se/sandbox/adp-staging/adp-cicd/bob-adp-release-auto:latest
  - java11-maven-builder: armdocker.rnd.ericsson.se/sandbox/adp-staging/adp-cicd/bob-java11mvnbuilder:latest
  - maven-builder: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/bob-javamvnbuilder.minideb:latest
  - trivy-inline-scan: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/trivy-inline-scan:latest
  - anchore-inline-scan: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/anchore-inline-scan:latest
  - go-builder: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/bob-gobuilder.adp-base-os:4.7.0
  - bth-linter: armdocker.rnd.ericsson.se/proj-eric-oss-dev/eric-bth/eric-bth-spectral-linter:0.1.0

# List of constants
properties:
  - helm-chart-name: eric-edca-catalog
  - image-name: eric-edca-catalog
  - helm-chart-repo: https://arm.sero.gic.ericsson.se/artifactory/proj-edca-ci-internal-helm/
  - helm-chart-drop-repo : https://arm.sero.gic.ericsson.se/artifactory/proj-edca-drop-helm/
  - image-registry: armdocker.rnd.ericsson.se
  - helm-chart-file-name: ${helm-chart-name}-${var.version}.tgz
  - config-file: ci-config/Vulnerability_Report.config # templated configuration file
  - output-file: build/report.md # output
  - image-to-scan: armdocker.rnd.ericsson.se/proj-edca-catalog-service/eric-edca-catalog:latest
  - tenable-sc-report: https://arm.sero.gic.ericsson.se/artifactory/proj-edca-catalog-va-generic-local/1.0.0-157/edca-tenable.csv
  - trivy-image: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/trivy-inline-scan:latest
  - anchore-image: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/anchore-inline-scan:latest

  #- image-repopath-dirty: sandbox/adp-staging/dirty/adp-cicd
  - image-repopath: proj-edca-catalog-service
  - image-repo-dirty: ${image-registry}/${image-repopath}/${image-name}
  - image-repo: ${image-registry}/${image-repopath}/${image-name}
  - git-user: lciadm100
  - git-repo-path: ADP-huboss/Microservices/edca-catalog-service
  - git-repo-url: ssh://${git-user}@gerrit.ericsson.se:29418/${git-repo-path}
  - git-repo: https://gerrit.ericsson.se/#/admin/projects/${git-repo-path}
  #- skipped-design-rules: "-DhelmDesignRule.config.drHc001=skip"
  - sonar-properties: "-Dsonar.login=${env.SONAR_AUTH_TOKEN}
                       -Dsonar.host.url=${env.SONAR_HOST_URL}
                       -Dsonar.projectKey=edca-catalog-service
                       -Dsonar.java.binaries=target/classes
                       -Dsonar.junit.reportsPath=target/surefire-reports
                       -Dsonar.surefire.reportsPath=target/surefire-reports
                       -Dsonar.java.coveragePlugin=jacoco
                       -Ddockerfile.skip
                       -Dsonarcoverage.jacoco.xmlReportPaths=target"
  - fossa-server-endpoint: https://scasfossa.internal.ericsson.com/
  - fossa-project-name: Data-Catalog
  - fossa-report-name: fossa-data-catalog-report.json
  - dependency-file-name: ci-config/dependencies.yaml
  - foss-primaries-file-name: ci-config/foss.primaries.yaml
  - license-agreement-file-name: doc/license.agreement.json
  - output-doc-file-name: doc/license-agreement-doc.md
  - fossa-team-name: EDCA-DataCatalog-CIRRUS
  - docker-params: "--workdir ${env.PWD}/ \
      --env GOBIN=${env.PWD}/ \
      --env GOCACHE=/tmp/.gocache
      --env CGO_ENABLED=0"

# Import environment variables (e.g. gitlab runner parameters)
env:
 - JENKINS_URL (default="https://fem2s11-eiffel004.eiffel.gic.ericsson.se:8443/jenkins/")
 - JOB_NAME (default="edca-catalog-cicd")
 - PWD
 - HOME
 - RELEASE (default=false)
 - KUBECONFIG (default=/tmp/admin.conf)
 - DOCKER_USERNAME
 - DOCKER_PASSWORD
 - GERRIT_USERNAME
 - GERRIT_PASSWORD
 - GERRIT_CHANGE_NUMBER
 - HELM_TOKEN
 - HELM_USER (default=enmadm100)
 - ENABLE_HELM_V3 (default=true)
 - XRAY_USER (default=enmadm100)
 - XRAY_TOKEN
 - FOSSA_API_KEY
# BTH Linter
 - OPEN_API_SPEC_LOCATION (default="./src/main/resources/v1/data-catalog-openapi.yaml")

# For SonarQube
 - SONAR_AUTH_TOKEN (default="")
 - SONAR_HOST_URL (default="https://codeanalyzer2.internal.ericsson.com")
 - SONAR_TARGET_BRANCH (default="master")

# Variables, set by below tasks
var:
 - version
 - commithash
 - rstate
 - version_prefix
 - namespace
 - fem_number
 - robot
 - branch

# Rules to execute
rules:

  # Clean workspace
  clean:
    - task: rm
      cmd:
        - rm -rf .bob/
        - rm -rf build/

  # Initialize, generate version and read commit has
  init:
    - task: version
      docker-image: adp-release-auto
      cmd: generate-version --is-release ${env.RELEASE} --output version
    - task: commit
      docker-image: adp-release-auto
      cmd: git rev-parse --short HEAD > .bob/var.commithash
    - task: adp-artifacts-properties
      docker-image: adp-release-auto
      cmd: generate-adp-artifacts --chart-name ${helm-chart-name} --chart-version ${var.version} --chart-repo ${helm-chart-drop-repo} --image-name ${image-name} --image-version firsttry --image-repo ${image-repo}
    - task: get-branch
      docker-image: adp-release-auto
      cmd: git rev-parse --abbrev-ref HEAD > .bob/var.branch

  fossa:
    - rule: fossa-init
    - rule: fossa-analyze
    - rule: fossa-scan-status-check
    - rule: fetch-fossa-report-attribution
    - rule: fetch-fossa-report-dependencies
    - rule: dependency-update
    - rule: dependency-validate
    - rule: dependency-generate-specific-foss
    - rule: dependency-update-specific-foss
    - rule: generate-svl-doc
    - rule: license-agreement-generate
    - rule: license-agreement-validate
    - rule: license-agreement-doc-generate

  fossa-init:
    - task: fossa-init
      docker-image: go-builder
      docker-flags:
        - ${docker-params}
        - "--env HOME=/tmp"
        - "--env GOPATH=/tmp"
      cmd:
        bash -c 'echo -e "machine gerrit.ericsson.se\nlogin ${env.GERRIT_USERNAME}\npassword ${env.GERRIT_PASSWORD}" > /tmp/.netrc;
        fossa init --endpoint ${fossa-server-endpoint} --project ${fossa-project-name}'

  fossa-analyze:
    - task: fossa-analyze
      docker-image: go-builder
      docker-flags:
        - ${docker-params}
        - "--env HOME=/tmp"
        - "--env GOPATH=/tmp"
        - "--env FOSSA_API_KEY=${env.FOSSA_API_KEY}"
      cmd:
        bash -c 'echo -e "machine gerrit.ericsson.se\nlogin ${env.GERRIT_USERNAME}\npassword ${env.GERRIT_PASSWORD}" > /tmp/.netrc;
        fossa analyze --revision ${var.version} --branch ${var.branch} --team ${fossa-team-name}'

  fossa-scan-status-check:
    - task: fossa-scan-status-check
      docker-image: adp-release-auto
      docker-flags:
        - "--env FOSSA_API_KEY=${env.FOSSA_API_KEY}"
      cmd: fossa_scan_status_check -s ${fossa-server-endpoint} -f custom -p ${fossa-project-name} -r ${var.version} -t ${env.FOSSA_API_KEY} -dl 15


  # New attribution format
  fetch-fossa-report-attribution:
    - task: fetch-fossa-report-attribution
      docker-image: go-builder
      docker-flags:
        - "--env FOSSA_API_KEY=${env.FOSSA_API_KEY}"
      cmd: fossa report attribution
            --config ${env.PWD}/src/.fossa.yml
            --endpoint ${fossa-server-endpoint}
            --project-url ${fossa-project-name}
            --branch ${var.branch}
            --revision ${var.version} --json > ${fossa-report-name}

  # Old dependencies format
  fetch-fossa-report-dependencies:
    - task: fetch-fossa-report-dependencies
      docker-image: go-builder
      docker-flags:
        - "--env FOSSA_API_KEY=${env.FOSSA_API_KEY}"
      cmd: fossa report dependencies
            --config ${env.PWD}/.fossa.yml
            --endpoint ${fossa-server-endpoint}
            --project-url ${fossa-project-name}
            --branch ${var.branch}
            --revision ${var.version} --json > dependencies_${fossa-report-name}

  # The script will check in Bazaar for 3PP that are registered and listed in ${dependency-file-name}
  # and update the bazaar section accordingly
  dependency-update:
    - task: dependency-update
      docker-image: adp-release-auto
      cmd: dependencies update
            --fossa-report ${fossa-report-name}
            --dependencies ${dependency-file-name}

  # The script will validate an existing ${dependency-file-name} document.
  # If it fail follow instruction in confluence and do scan-bazaar
  dependency-validate:
    - task: dependency-validate
      docker-image: adp-release-auto
      cmd: dependencies validate
           --dependencies ${dependency-file-name}

  # Generate specific foss document
  dependency-generate-specific-foss:
    - task: dependency-generate-specific-foss
      docker-image: adp-release-auto
      cmd: dependencies generate-specific-foss
            --output-directory doc/
            --dependencies ${dependency-file-name}
            --primary-foss ${foss-primaries-file-name}

  # Update dependency.yaml file with svl arguments
  dependency-update-specific-foss:
    - task: dependency-update-specific-foss
      docker-image: adp-release-auto
      cmd: dependencies update
            -d ${dependency-file-name}
            -as

  # Generate Software Vendor List (SVL)
  generate-svl-doc:
    - task: generate-svl-doc
      docker-image: adp-release-auto
      cmd: dependencies generate-svl
            -d ${dependency-file-name}
            --primary-foss ${foss-primaries-file-name}
            -out doc/

  license-agreement-generate:
    - task: license-agreement-generate
      docker-image: adp-release-auto
      cmd: license-agreement generate
            --dependencies ${dependency-file-name}
            --fossa-report ${fossa-report-name}
            --output ${license-agreement-file-name}

  license-agreement-validate:
    - task: license-agreement-validate
      docker-image: adp-release-auto
      cmd: license-agreement validate
            --license-agreement ${license-agreement-file-name}

  license-agreement-doc-generate:
    - task: license-agreement-doc-generate
      docker-image: adp-release-auto
      cmd: license-agreement doc-generate
             --license-agreement ${license-agreement-file-name}
             --output ${output-doc-file-name}

  lint:
    - task: helm
      docker-image: adp-release-auto
      docker-flags:
        - --env ENABLE_HELM_V3=true
      cmd: helm lint charts/${helm-chart-name}
    - task: helm-chart-check
      docker-image: adp-helm-dr-check
      #cmd: helm-dr-check --helm-chart charts/${helm-chart-name} ${skipped-design-rules} --helm-v3 --output .bob/
      #DR-D1123-124 - Skipping the Design rule
      cmd: helm-dr-check -DhelmDesignRule.config.DR-D1123-124=skip --helm-chart charts/${helm-chart-name} --helm-v3 --output .bob/

  bth-linter:
    - task: bth-linter
      docker-image: bth-linter
      cmd: spectral lint -r /com.ericsson.bss.rm.oap.bth.linter/rule_tea.yaml ${env.OPEN_API_SPEC_LOCATION} --format > .bob/bth-linter-data-catalog.html

  # Build a docker image pointing to internal repository
  image:
    - task: docker-build-dirty
      cmd: docker build ${env.PWD}
        --file Dockerfile
        --tag ${image-repo-dirty}:${var.version}
        --build-arg REPOSITORY=${git-repo}
        --build-arg COMMIT=${var.commithash}
        --build-arg APP_VERSION=${var.version}

  # Create official package
  # Call publish only when merged to master
  # Push image to ci-internal repo and create local version of helm chart
  package:
    - task: image-push-dirty
      cmd: docker push ${image-repo}:${var.version}
    - task: package-helm-dirty
      docker-image: adp-release-auto
      docker-flags:
        - "--env HELM_USER"
        - "--env HELM_TOKEN"
        - "--env ENABLE_HELM_V3=${env.ENABLE_HELM_V3}"
      cmd: helm-package
        --folder charts/${helm-chart-name}
        --workdir .bob --output .bob/${helm-chart-name}-dirty
        --version ${var.version}
        --replace VERSION=${var.version}

  #Delete previously created name space for CICD
  delete-namespace:
    - task: set-var
      cmd:
        - echo ${env.JENKINS_URL} | cut -f3 -d'/' |cut -f1 -d'-' > .bob/var.fem_number
    - task: set-namespace
      cmd:
        - echo ${var.fem_number}-${env.JOB_NAME} | sed s/_/-/g  > .bob/var.namespace
    - task: create-robot-ns
      cmd:
        - echo robot-env > .bob/var.robot
    - task: delete-namespace
      docker-image: k8-test
      docker-flags:
        - "--env KUBECONFIG=/tmp/admin.conf"
        - "--volume ${env.KUBECONFIG}:/tmp/admin.conf:ro"
        - "--volume ${env.PWD}:${env.PWD}"
      cmd:
        - kubectl delete namespace ${var.namespace}

  # Creating namespace dynamically
  create-namespace:
    - task: create-namespace
      docker-image: k8-test
      docker-flags:
        - "--env KUBECONFIG=/tmp/admin.conf"
        - "--volume ${env.KUBECONFIG}:/tmp/admin.conf:ro"
        - "--volume ${env.PWD}:${env.PWD}"
      cmd:
        - kubectl create  namespace ${var.namespace}

  # Install EDCA Integration helm chart
  helm-install:
    - task: helm-install
      docker-image: k8-test
      docker-flags:
        - "--env KUBECONFIG=/tmp/admin.conf"
        - "--volume ${env.KUBECONFIG}:/tmp/admin.conf:ro"
        - "--volume ${env.PWD}:${env.PWD}"
      cmd:
        - kubectl create -f CICD/secret.yaml --namespace ${var.namespace}
        - helm install edca-db https://arm.sero.gic.ericsson.se/artifactory/proj-adp-gs-all-helm/eric-data-document-database-pg/eric-data-document-database-pg-5.3.0+54.tgz -f CICD/db_env.yaml --debug --wait --namespace ${var.namespace}
        - helm install edca-catalog .bob/eric-edca-catalog-dirty/${helm-chart-name}-${var.version}.tgz -f CICD/catalog_env.yaml --debug --wait --namespace ${var.namespace}

  # Deploy robot-env and execute robot P1 and P2 test cases
  deploy-robot:
    - task: deploy-robot
      docker-image: k8-test
      docker-flags:
        - "--env KUBECONFIG=/tmp/admin.conf"
        - "--volume ${env.KUBECONFIG}:/tmp/admin.conf:ro"
        - "--volume ${env.PWD}:${env.PWD}"
      cmd:
        - kubectl create ns ${var.robot}
        - kubectl apply -f ${env.PWD}/catalog-test/robot-pod.yaml -n ${var.robot}
        - kubectl cp ${env.PWD}/catalog-test ${var.robot}/robot-env:/opt/catalog-test

  P1-Execution:
    - task: P1-Execution
      docker-image: k8-test
      docker-flags:
        - "--env KUBECONFIG=/tmp/admin.conf"
        - "--volume ${env.KUBECONFIG}:/tmp/admin.conf:ro"
        - "--volume ${env.PWD}:${env.PWD}"
      cmd:
        - kubectl exec robot-env -n ${var.robot} -- bash -c "python3 catalog-test/Acceleration_Tests/P1/robot-gen.py catalog-test/Acceleration_Tests/P1/rest-endpoint-input.yaml catalog-test/Acceleration_Tests/P1/rest-api-testcases.robot"
        - kubectl exec robot-env -n ${var.robot} -- bash -c "python3 -m robot.run -v namespace:${var.namespace} --outputdir catalog-test/Acceleration_Tests/P1/ catalog-test/Acceleration_Tests/P1"

  P2-Execution:
    - task: P2-Execution
      docker-image: k8-test
      docker-flags:
        - "--env KUBECONFIG=/tmp/admin.conf"
        - "--volume ${env.KUBECONFIG}:/tmp/admin.conf:ro"
        - "--volume ${env.PWD}:${env.PWD}"
      cmd:
        - kubectl exec robot-env -n ${var.robot} -- bash -c "python3 catalog-test/Acceleration_Tests/P2/robot-gen.py catalog-test/Acceleration_Tests/P2/input.yaml catalog-test/Acceleration_Tests/P2/rest-api-testcases.robot"
        - kubectl exec robot-env -n ${var.robot} -- bash -c "python3 -m robot.run -v namespace:${var.namespace} --NoStatusRC --outputdir catalog-test/Acceleration_Tests/P2 catalog-test/Acceleration_Tests/P2"
        - kubectl exec robot-env -n ${var.robot} -- bash -c  "rebot --outputdir results --output final_output.xml catalog-test/Acceleration_Tests/P1/output.xml catalog-test/Acceleration_Tests/P2/output.xml"
        - kubectl exec -n ${var.robot} robot-env -- tar cf - results/ | tar xf - -C ${env.PWD}/catalog-test
        - kubectl delete ns ${var.robot}

  #Delete previously created name space for CICD
  perf-execution:
    - task: perf-execution
      cmd:
        - locust -f ${env.PWD}/catalog-test/Performance_Tests/catalog-concurrent_load_test.py -u 11 -r 1 --headless --nameSpace ${var.namespace} --dataDirectory ${env.PWD}/catalog-test/Performance_Tests/Catalog_data --reportStats ${env.PWD}/catalog-test/Performance_Tests/report_stats --logfile=${env.PWD}/catalog-test/Performance_Tests/logging/catalog-concurrent_load_test.log --loglevel=DEBUG -t 150s
        - locust -f ${env.PWD}/catalog-test/Performance_Tests/catalog-continous_load_test.py -u 1 -r 1 --headless --nameSpace ${var.namespace} --dataDirectory ${env.PWD}/catalog-test/Performance_Tests/Catalog_data --reportStats ${env.PWD}/catalog-test/Performance_Tests/report_stats --logfile=${env.PWD}/catalog-test/Performance_Tests/logging/catalog-continous_load_test.log --loglevel=DEBUG

  helm-upgrade:
    - task: helm-upgrade
      docker-image: k8-test
      docker-flags:
        - "--env KUBECONFIG=/tmp/admin.conf"
        - "--volume ${env.KUBECONFIG}:/tmp/admin.conf:ro"
        - "--volume ${env.PWD}:${env.PWD}"
      cmd:
        - kubectl create -f CICD/secret.yaml --namespace ${var.namespace}
        - helm install edca-db https://arm.sero.gic.ericsson.se/artifactory/proj-adp-gs-all-helm/eric-data-document-database-pg/eric-data-document-database-pg-5.3.0+54.tgz -f CICD/db_env.yaml --debug --wait --namespace ${var.namespace}
        - helm install edca-catalog https://arm.sero.gic.ericsson.se/artifactory/proj-edca-drop-helm/eric-edca-catalog/eric-edca-catalog-1.0.0-130.tgz -f CICD/catalog_env.yaml --debug --wait --namespace ${var.namespace}
        - helm ls --namespace ${var.namespace} 
        - helm history edca-catalog --namespace ${var.namespace}
        - helm upgrade edca-catalog https://arm.sero.gic.ericsson.se/artifactory/proj-edca-drop-helm/eric-edca-catalog/eric-edca-catalog-1.0.0-175.tgz -f CICD/catalog_env.yaml --debug --wait --namespace ${var.namespace}
        - helm ls --namespace ${var.namespace} 
        - helm history edca-catalog --namespace ${var.namespace}

  zap-scan:
    - task: system-test-with-vulnerability-check
      docker-image: k8s-test
      docker-flags:
        - "--env KUBECONFIG=${env.KUBECONFIG}"
        - "--volume ${env.KUBECONFIG}:${env.KUBECONFIG}:ro"
        - "--volume ${env.PWD}:${env.PWD}"
      cmd: /test.py --kubernetes-admin-conf=${env.KUBECONFIG}
           --helm-user=${env.HELM_USER}
           --arm-api-token=${env.HELM_TOKEN}
           --kubernetes-namespace=fem2s11-edca-catalog-drop
           --only-zap-test
           --zap-config=zap/zap_config.yaml

  # Run Nmap port scan test using TCP,UDP, and SCTP protocols
  nmap-port-scan:
    - task: nmap-port-scan
      docker-image: k8-test
      docker-flags:
        - "--env KUBECONFIG=/tmp/admin.conf"
        - "--volume ${env.KUBECONFIG}:/tmp/admin.conf:ro"
        - "--volume ${env.PWD}:${env.PWD}"
      cmd:
        - test.py --helm-v3 --kubernetes-admin-conf=/tmp/admin.conf
          --helm-user=${env.HELM_USER}
          --arm-api-token=${env.HELM_TOKEN}
          --kubernetes-namespace=${var.namespace}
          --nmap-test
          --nmap-config-file='nmap/nmap_config_all_protocols.yaml'
          --kube-exec-timeout=1800

  trivy-inline-scan:
    - task: fetch-image
      cmd:
      - "docker pull ${image-to-scan}"
      - mkdir -p build/trivy-reports
    # Scan an image and print result to console
    - task: trivy-inline-scan-console-report
      docker-image: trivy-inline-scan
      docker-in-docker: socket
      cmd: ${image-to-scan}
    # Scan an image and save result to json
    - task: trivy-inline-scan-json-report
      docker-image: trivy-inline-scan
      docker-in-docker: socket
      cmd: --format json --output build/trivy-reports/trivy.report.json ${image-to-scan}

  anchore-inline-scan:
    - task: fetch-image
      cmd: docker pull ${image-to-scan}
    - task: anchore-inline-scan
      docker-image: anchore-inline-scan
      docker-in-docker: socket
      cmd: scan ${image-to-scan}

  fetch-tenable-sc-report:
    - task: create-report-dir
      cmd: mkdir -p build/tenablesc-reports/
    - task: fetch-tenable-sc
      cmd: "curl -u '${env.HELM_USER}:${env.HELM_TOKEN}'
      ${tenable-sc-report}
      -o build/tenablesc-reports/tenablesc-report.csv"

  cleanup-anchore-trivy-images:
    - task: clean-images
      cmd:
      - "docker image rm -f ${anchore-image}"
      - "docker image rm -f ${trivy-image}"
      - "docker image rm -f ${image-to-scan}"

  va-report:
    - task: fetch_vulnerability
      docker-image: adp-release-auto
      cmd: fetch-xray --user ${env.XRAY_USER} --apikey ${env.XRAY_XRAY_TOKEN} --config ${env.PWD}/${config-file} --output ${env.PWD}/${output-file} xray_report.json
      cmd: va-report --config ${env.PWD}/${config-file} --md --debug --output Vulnerability_Report.md --set version=1.0.0-210 --zap-reports zap/reports --nmap-reports nmap_reports/nmap_report --trivy-reports build/trivy-reports --anchore-reports anchore-reports --tenable-sc build/tenablesc-reports/ ; exit 0

  publish-internal:
    - task: helm-upload-internal
      docker-image: adp-release-auto
      cmd: upload_file.sh
        --filename=.bob/${helm-chart-name}-dirty/${helm-chart-file-name}
        --repository=${helm-chart-repo}${helm-chart-name}
        --api-token=${env.HELM_TOKEN}

  publish:
    - task: package-helm-public
      docker-image: adp-release-auto
      docker-flags:
        - "--env HELM_USER"
        - "--env HELM_TOKEN"
        - "--env ENABLE_HELM_V3=${env.ENABLE_HELM_V3}"
      cmd: helm-package
        --folder charts/${helm-chart-name}
        --workdir .bob --output build
        --version ${var.version}
        --replace VERSION=${var.version}

    - task: image-pull-dirty
      cmd: docker pull ${image-repo-dirty}:${var.version}
    - task: image-tag-public
      cmd: 
        - docker tag ${image-repo-dirty}:${var.version} ${image-repo}:${var.version}
        - docker tag ${image-repo-dirty}:${var.version} ${image-repo}:latest     
    - task: image-push-public
      cmd: 
        - docker push ${image-repo}:${var.version}
        - docker push ${image-repo}:latest

    #- task: git-tag
    #  docker-image: adp-release-auto
    #  cmd:
    #    - git tag -a ${var.version} -m "Release ${var.version}"
    #    - git push origin ${var.version}

    - task: helm-upload
      docker-image: adp-release-auto
      docker-flags:
        - "--env ENABLE_HELM_V3=${env.ENABLE_HELM_V3}"
      cmd: upload_file.sh
        --filename=build/${helm-chart-file-name}
        --repository=${helm-chart-drop-repo}${helm-chart-name}
        --api-token=${env.HELM_TOKEN}

  # Run SonarQube Full Analysis
  #
  # Command Line Arguments:
  #  -Dsonar.login:    SonarQube Login Token, (optional)
  #  -Dsonar.host.url: SonarQube URL
  #  -Dsonar.projectVersion: Project version is to differentiate SonarQube results from one
  #                          developer run to another. projectVersion is determined as
  #                          "Version Prefix"-"Gerrit Change Number", eg: 1.0.0-5532279
  #  -Ddockerfile.skip: Project specific flag to skip docker image creation
  #  -Dsonarcoverage.jacoco.xmlReportPaths: Path to JaCoCo reports for code coverage
  #  -Duser.home: Home directory to be used when sonar run in a container
  sonar: #sonar-branch
    - task: generate-version-prefix
      cmd: cat VERSION_PREFIX > .bob/var.version_prefix
    - task: sonarqube-analysis
      docker-image: maven-builder
      docker-flags:
        - -v /etc/passwd:/etc/passwd:ro
        - "--volume ${env.HOME}:${env.HOME}"
      cmd: mvn -T 5 -Duser.home=${env.HOME} sonar:sonar
        ${sonar-properties}
        -Dsonar.branch.name=${var.version_prefix}-${env.GERRIT_CHANGE_NUMBER}
        -B -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=debug
